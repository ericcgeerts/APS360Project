# -*- coding: utf-8 -*-
"""Car_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rgy-tbKjXJ1LnRi8-KrsWLwGztpQYTli

Dataset is available here: https://ai.stanford.edu/~jkrause/cars/car_dataset.html

Data set has around 16k images (8k for training & 8k for testing)
Can split take 2k images for validation

The Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.

Citation:
3D Object Representations for Fine-Grained Categorization
Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei
4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.
"""

""" imports """
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import random
import scipy.io                               # required to read the .mat files
import torchvision                                      # for importing dataset
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
import torchvision.models as models
import json

import os
import random
from PIL import Image

from google.colab import drive
drive.mount('/content/gdrive/', force_remount=True)

home_path = '/content/gdrive/My Drive/3rd Year/2nd Semester/APS360/APS360 Project/Code/Data/'


os.chdir(home_path)
!pwd

"""# Part A: Data cleaning & setup

## Information about dataset
- The given dataset contains the following files:
  
  1. cars_meta.mat: contains all 196 original labels
  2. cars_train_annos.mat: Contains the variable 'annotations', which is a struct array of length num_images and where each element has the fields
  3. cars_test_annos.mat: Same format as 'cars_train_annos.mat', except the class is not provided.

- However, this project does not need the 196 labels, but instead cares about only the brand name. Thus, the labels will have to be adjusted as a first step.

## File name: 'cars_meta.mat'

### Description: Contains all 196 original labels

This is stored in a particular format (which we'll see soon enough). The goal is to extract all the 196 classes into a data structure which will be modified into the adjusted classes.
"""

file = scipy.io.loadmat('cars_meta.mat')

print(file)

print(type(file['class_names']))
classes = file['class_names'][0]

def split_string_categories(input):
  """
  - example:
  - input: 'Bentley Arnage Sedan 2009'
  - output: 'Bentley', 'Arnage Sedan', '2009'
  """
  split_string = input.split()
  separator = ' '
  brand_name = split_string[0]
  year = split_string[-1]
  model_name = separator.join(split_string[1:(len(split_string)-1)])

  return brand_name, model_name, year

print("There are", len(classes), "number of classes in the dataset")

def data_clean(classes):
  """
  - Returns 3 data structures:
  1. adjusted_classes: Dictonary that maps the brand name to the adjusted class
  2. brand_names: Dictonary that maps the adjusted class to the brand name
  3. original_classes: array that maps original classes to adjusted
  """
  adjusted_class_number = 1 # starts from 0
  # data structs to store relevant data
  adjusted_classes = {} # from brand name to adjusted class number
  brand_names = {} # from adjusted class number to brand name
  # need a dictionary of lists that map new class to original class
  original_classes = [] # from original class to adjusted class number
  original_classes.append(-1) # there is no class 0 so add a null value

  for c in classes:

    brand_name, model_name, year = split_string_categories(c[0])

    if brand_name not in adjusted_classes.keys():
      adjusted_classes[brand_name] = adjusted_class_number
      brand_names[adjusted_class_number] = brand_name

      original_classes.append(adjusted_class_number)
      adjusted_class_number += 1

    else:
      original_classes.append(adjusted_classes[brand_name])

  print(adjusted_classes)
  print(brand_names)
  print(original_classes)
  return adjusted_classes, brand_names, original_classes

adjust_classes, brand_names, original_classes = data_clean(classes)
print("Adjusted class (defined as unique brand) number is:",len(adjust_classes))

def get_adjusted_from_original(original_class_no):
  """
  - Given the original class number, return the adjusted class number & brand name
  - Example: input: 196
  - Outputs: (49, smart)
  """
  adjusted_class_no = original_classes[original_class_no]
  if adjusted_class_no == -1:
    print("Error! Incorrect original class no.")
    return adjusted_class_no, "DNE"
  return adjusted_class_no, brand_names[adjusted_class_no]

original_class = 196
adjusted_class, brand_name = get_adjusted_from_original(original_class)
print("Original class:",
      original_class,
      ". Adjusted class:",
      adjusted_class,
      ". Brand (class) name is:",
      brand_name)

def get_brand_name_from_adjusted_class(adjusted_class_no):
  """
  - Given the adjusted class number return the brand name
  - Example: input: 49
  - Output: smart
  """
  return brand_names[adjusted_class_no]

def get_adjusted_label(labels):
  """
  - Given the original labels (tensors that takes values from 1 to 196)
  - (i.e. original labels), return a tensor with the adjusted labels (values
  from 1 to 49).
  """
  actual_label = []
  for i in range(len(labels)):
    adjusted_class, brand_name = get_adjusted_from_original(labels[i].item()+1)
    # different from data structs
    actual_label.append(adjusted_class)
  adjusted_label = torch.tensor(actual_label)
  return adjusted_label

def showPictures(data_loader, size=3):
  # plot the images in the batch, along with the corresponding labels
  dataiter = iter(data_loader)
  images,labels = dataiter.next()
  labels = get_adjusted_label(labels) # important step!!!!! similar to normalizing
  # print(labels)
  images = images.numpy() # convert images to numpy for display
  for i in range(size): ## size pictures of the batch
    plt.figure()
    plt.imshow(np.transpose(images[i], (1, 2, 0)), cmap='gray')
    # plt.imshow(images[i], cmap='gray')
    # plt.imshow((out * 255).astype(np.uint8))
    plt.title(get_brand_name_from_adjusted_class(labels[i].item()))

path = home_path + 'car_data/'

train_path = path + 'train/'
test_path = path + 'test/'

print(train_path)
print(test_path)

train_transforms = transforms.Compose([transforms.Resize((244,244)),
                                       transforms.RandomHorizontalFlip(), #flipping a car does not change the brand
                                       transforms.RandomRotation(30), #rotate to reduce noise
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) #grayscale

val_test_transforms = transforms.Compose([transforms.Resize((244,244)),
                                      transforms.CenterCrop(224),
                                      # transforms.Grayscale(num_output_channels=1),
                                      transforms.ToTensor(),
                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


train_data = torchvision.datasets.ImageFolder(train_path, transform=train_transforms)
test_data = torchvision.datasets.ImageFolder(test_path, transform=val_test_transforms)

lengths = [int(len(test_data)*0.2)+1, int(len(test_data)*0.8)]

val_data, test_data = torch.utils.data.random_split(test_data, lengths)


train_data_loader = torch.utils.data.DataLoader(train_data,
                                          batch_size=32,
                                          shuffle=True,
                                          num_workers=4)
test_data_loader = torch.utils.data.DataLoader(test_data,
                                          batch_size=32,
                                          shuffle=True,
                                          num_workers=4)

val_data_loader = torch.utils.data.DataLoader(val_data,
                                          batch_size=32,
                                          shuffle=True,
                                          num_workers=4)

showPictures(train_data_loader)
# plot the images in the batch, along with the corresponding labels

"""## Statistics about current data:

  1. Determine the number of elements in each class: This indicates that the number of samples in each class is not consistent. So must duplicate samples so that each class contains the same number of samples as the most frequent class, or compromise efficiency and ceil it to a reasonable number.
  2. Find mean, standard deviation, max & min values and see if the distribution is ideal.
"""

def get_classes_count(dataset):
  counts = {}
  for _, labels in iter(dataset):
    # print("original labels are:",labels)
    labels = get_adjusted_label(labels) # important step!!!!! similar to normalizing
    # print("adjusted labels are:",labels)
    for label in labels:
      if label.item() not in counts.keys():
        # print("New key added with key #",label.item())
        counts[label.item()] = 1
      else:
        counts[label.item()] += 1
  return counts

train_counts = get_classes_count(train_data_loader)

train_counts = get_classes_count(train_data_loader)
val_counts = get_classes_count(val_data_loader)
test_counts = get_classes_count(test_data_loader)

print(val_counts)

def get_x_y_data(counts):
  total = 0
  x_axis = []
  y_axis = []
  j = 0
  for i in sorted (counts):
    x_axis.append(i)
    y_axis.append(counts[i])
    if j == 16:
      # print("\n")
      j = 0
    # print ((i, counts[i]), end = " ")
    j+=1
    total += counts[i]
  print("Total items:",total)
  return x_axis, y_axis

def plot_data_counts(x_axis, y_axis):
  plt.figure()
  plt.scatter(x_axis, y_axis)
  plt.title("Data count by class")

def analyze_data(counts):
  x, y = get_x_y_data(counts)
  plot_data_counts(x, y)
  y_np = np.array(y)
  print("Max count of class occurence is:", y_np.max())
  print("Min count of class occurence is:", y_np.min())
  print("Avg count of class occurence is:", y_np.mean())
  print("Std var of class occurence is:", y_np.std())

def print_counts(counts):
  x, y = get_x_y_data(counts)
  print()
  for i in range(len(x)):
    print("Brand Name:",
          get_brand_name_from_adjusted_class(i+1),
          " has count:",
          y[i])

print("Train data analysis")
analyze_data(train_counts)

"""
Must remove images with high counts (> 400)
BMW: 531
Audi: 589
Chevrolet: 905
Dodge: 630
Ford: 521
Hyundai: 438
"""

print("Val data analysis")
analyze_data(val_counts)

print("Testing data analysis")
analyze_data(test_counts)

"""#Part B: Baseline Model"""

from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np

from sklearn import svm, metrics, datasets
from sklearn.utils import Bunch
from sklearn.model_selection import GridSearchCV, train_test_split
from PIL import Image
from numpy import asarray
import skimage
import skimage.io
from skimage.transform import resize
from sklearn.svm import LinearSVC

from PIL import Image

from sklearn.svm import SVC
from sklearn.decomposition import PCA as RandomizedPCA
from sklearn.pipeline import make_pipeline

def load_image_files(container_path):
  flat_data = []
  target = []

  for i in range(len(train_data_loader.dataset.imgs)):
    img = skimage.io.imread(train_data_loader.dataset.imgs[i][0])
    img_resized = resize(img, (244,244), anti_aliasing=True, mode='reflect')
    check = get_adjusted_from_original(train_data_loader.dataset.imgs[i][1]+1)
    arr = np.array(img_resized)
    if len(arr.shape) > 2:
      arr = arr[:, :, 0]*0.299 + arr[:, :, 1]*0.587 + arr[:, :, 2]*0.114
    flat_data.append(arr.flatten())
    target.append(check[0])
    if i % 500 == 0:
      print(i)

  for i in range(len(test_data_loader.dataset.dataset.imgs)):
    img = skimage.io.imread(test_data_loader.dataset.dataset.imgs[i][0])
    img_resized = resize(img, (244,244), anti_aliasing=True, mode='reflect')
    check = get_adjusted_from_original(test_data_loader.dataset.dataset.imgs[i][1]+1)
    arr = np.array(img_resized)
    if len(arr.shape) > 2:
      arr = arr[:, :, 0]*0.299 + arr[:, :, 1]*0.587 + arr[:, :, 2]*0.114
    flat_data.append(arr.flatten())
    target.append(check[0])
    if i % 500 == 0:
      print(i)


  flat_data = np.array(flat_data)
  target = np.array(target)
  return Bunch(data=flat_data,
            target=target)

image_dataset = load_image_files(train_path)

X_train, X_test, y_train, y_test = train_test_split(
    image_dataset.data, image_dataset.target, test_size=0.3)

print('Training data and target sizes: \n{}, {}'.format(X_train.shape,y_train.shape))
print('Test data and target sizes: \n{}, {}'.format(X_test.shape,y_test.shape))

# Commented out IPython magic to ensure Python compatibility.
pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)
svc = SVC(kernel='rbf', class_weight='balanced')
model = make_pipeline(pca, svc)
param_grid = {'svc__C': [1, 5, 10, 50],
              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}
grid = GridSearchCV(model, param_grid)

# %time grid.fit(X_train, y_train)
print(grid.best_params_)

model = grid.best_estimator_
y_pred = model.predict(X_test)

print("Classification report for - \n{}:\n{}\n".format(
    grid, metrics.classification_report(y_test, y_pred)))

"""#Part C: Primary Model"""

# With more convulation and pooling layers
class CarModelDetector(nn.Module):
    def __init__(self):
        super(CarModelDetector, self).__init__()
        # in_channels = input image channels
        # out_channels = conv filters outputs/feature maps
        self.conv1 = nn.Conv2d(3, 5, 5)
        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)
        self.conv2 = nn.Conv2d(5, 10, 5)
        self.conv3 = nn.Conv2d(10, 20, 5)

        self.fc1 = nn.Linear(20 * 24 * 24, 2 * 24 * 24)
        self.fc2 = nn.Linear(2 * 24 * 24, 50)

    def forward(self, img):
        x = self.pool(F.relu(self.conv1(img)))
        # Feature map size = 220 (input image 224 x 224)
        # Feature map size after pooling = 110
        x = self.pool(F.relu(self.conv2(x)))
        # Feature map size = 106
        # Feature map size after pooling = 53
        x = self.pool(F.relu(self.conv3(x)))
        # Feature map size = 49
        # Feature map size after pooling = 24
        x = x.view(-1, 20 * 24 * 24)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)

        return x

def train(model, train_loader, val_loader, batch_size=32, num_epochs=1, learn_rate = 0.001):
    use_cuda = True
    torch.manual_seed(1000)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learn_rate)

    train_acc, val_acc, iters = [], [], []

    # training
    print ("Training Started...")
    n = 0 # the number of iterations
    for epoch in range(num_epochs):
        for imgs, labels in iter(train_loader):
            labels = get_adjusted_label(labels)
            if use_cuda and torch.cuda.is_available():
              imgs = imgs.cuda()
              labels = labels.cuda()
            out = model(imgs)             # forward pass
            #if epoch == 0:
              #print("Dimension of label is:", len(labels))
              #print("Dimension of output is:",len(out))
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch
            iters.append(n)
            n += 1

        # track accuracy
        train_acc.append(get_accuracy(model, train_loader))
        val_acc.append(get_accuracy(model, val_loader))
        print(epoch, train_acc[-1], val_acc[-1])

    plt.title("Training Curve for Primary Model- batch_size=512, num_epochs=10, learn_rate = 0.0001")

    plt.plot(range(1, len(train_acc)+1), train_acc, label="Train")
    plt.plot(range(1, len(train_acc)+1), val_acc, label="Validation")
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy")
    plt.legend(loc='best')
    plt.show()



    return train_acc, val_acc

def get_accuracy(model, data_loader):
    correct = 0
    total = 0
    for imgs, labels in data_loader:
        labels = get_adjusted_label(labels)
        use_cuda = True
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()

        output = model(imgs)
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

CarModel = CarModelDetector()
use_cuda = True
if use_cuda and torch.cuda.is_available():
  CarModel.cuda()

train(CarModel, train_data_loader, val_data_loader, batch_size=512, num_epochs=10, learn_rate = 0.001)

CarModel = CarModelDetector()
use_cuda = True
if use_cuda and torch.cuda.is_available():
  CarModel.cuda()


train(CarModel, train_data_loader, val_data_loader, batch_size=512, num_epochs=10, learn_rate = 0.01)

CarModel = CarModelDetector()
use_cuda = True
if use_cuda and torch.cuda.is_available():
  CarModel.cuda()


train(CarModel, train_data_loader, val_data_loader, batch_size=512, num_epochs=10, learn_rate = 0.0001)

valid_honda = torch.utils.data.DataLoader(
    [e for e in val_data.dataset if original_classes[e[1]+1] == 13],
    val_data.fields)
# Create a Dataset of only non-spam validation examples
valid_hyundai = torch.utils.data.DataLoader(
    [e for e in val_data.dataset if original_classes[e[1]+1] == 10],
    val_data.fields)

"""# **RESNET MODEL:**

"""

def evaluate(model, val_loader, criterion):
    valid_loss = 0
    accuracy = 0

    # change model to work with cuda
    model.to('cuda')

    # Iterate over data from validloader
    for ii, (images, labels) in enumerate(val_loader):

        # Change images and labels to work with cuda
        labels = get_adjusted_label(labels)
        images, labels = images.to('cuda'), labels.to('cuda')

        # Forward pass image though model for prediction
        output = model.forward(images)
        # Calculate loss
        valid_loss += criterion(output, labels).item()
        # Calculate probability
        ps = torch.exp(output)

        # Calculate accuracy
        equality = (labels.data == ps.max(dim=1)[1])
        accuracy += equality.type(torch.FloatTensor).mean()

    return valid_loss, accuracy

def train_res_net(model, train_loader, val_loader, batch_size=32, num_epochs=10, learn_rate = 0.01):
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(model.parameters(), lr=learn_rate, momentum=0.9)
  lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)

  # use_cuda = True
  torch.manual_seed(1000)

  steps = 0
  print_every = 40

  train_loss, train_acc, val_loss, val_acc, iters = [], [], [], [], []
  # change to gpu mode
  model.to('cuda')
  model.train()

  for e in range(num_epochs):

      running_loss = 0
      running_correct = 0
      running_total = 0

      # Iterating over data to carry out training step
      for ii, (images, labels) in enumerate(train_loader):
          steps += 1
          labels = get_adjusted_label(labels)
          images, labels = images.to('cuda'), labels.to('cuda')

          # zeroing parameter gradients
          optimizer.zero_grad()

          # Forward and backward passes
          outputs = model.forward(images)
          loss = criterion(outputs, labels)
          loss.backward()
          optimizer.step()

          running_loss += loss.item()

          # track accuracy:
          pred = outputs.max(1, keepdim=True)[1]
          running_correct += pred.eq(labels.view_as(pred)).sum().item()
          running_total += images.shape[0]

      iters.append(e)
      valid_loss, val_accuracy = evaluate(model, val_loader, criterion)

      train_acc.append(running_correct/running_total)
      val_acc.append(val_accuracy/len(val_loader))

      train_loss.append(running_loss/running_total)
      val_loss.append(valid_loss/len(val_loader))

      lrscheduler.step(val_accuracy * 100)
      print("Epoch:",e+1,
            ". Training Accuracy is:", train_acc[-1],
            ". Validation Accuracy is:", val_acc[-1])

  print("Training done. Time to plot results!")
  return iters, val_loss, val_acc, train_acc, train_loss

def plot_results(x, training, validation, title):
  plt.figure()
  plt.plot(x, training, label='training')
  plt.plot(x, validation, label='validation')
  plt.title(title)
  plt.xlabel('Epochs')
  plt.ylabel(title)
  plt.legend(loc='best')

pretrained_model = models.resnet34(pretrained=True)

num_features = pretrained_model.fc.in_features
pretrained_model.fc = nn.Linear(num_features, 50)

iters, val_loss, val_acc, train_acc, train_loss = train_res_net(
    pretrained_model,
    train_data_loader,
    val_data_loader)

plot_results(iters, train_acc, val_acc, "Accuracy")
plot_results(iters, train_loss, val_loss, "Loss")

pretrained_model2 = models.resnet34(pretrained=True)

num_features = pretrained_model2.fc.in_features
pretrained_model2.fc = nn.Linear(num_features, 50)

iters2, val_loss2, val_acc2, train_acc2, train_loss2 = train_res_net(
    pretrained_model2,
    train_data_loader,
    val_data_loader, batch_size = 512, num_epochs = 10, learn_rate = 0.001)

plot_results(iters2, train_acc2, val_acc2, "Accuracy")
plot_results(iters2, train_loss2, val_loss2, "Loss")

#This resnet has 50 layers
pretrained_model3 = models.resnet50(pretrained=True)

num_features = pretrained_model3.fc.in_features
pretrained_model3.fc = nn.Linear(num_features, 50)

iters3, val_loss3, val_acc3, train_acc3, train_loss3 = train_res_net(
    pretrained_model3,
    train_data_loader,
    val_data_loader, batch_size = 128, num_epochs = 10, learn_rate = 0.001)

print("")
plot_results(iters3, train_acc3, val_acc3, "Accuracy-50 layers")
plot_results(iters3, train_loss3, val_loss3, "Loss-50 layers")

pretrained_model4 = models.resnet50(pretrained=True)

num_features = pretrained_model4.fc.in_features
pretrained_model4.fc = nn.Linear(num_features, 50)

iters4, val_loss4, val_acc4, train_acc4, train_loss4 = train_res_net(
    pretrained_model4,
    train_data_loader,
    val_data_loader)

print("")
plot_results(iters4, train_acc4, val_acc4, "Accuracy-50 layers")
plot_results(iters4, train_loss4, val_loss4, "Loss-50 layers")

pretrained_model5 = models.resnet50(pretrained=True)

num_features = pretrained_model5.fc.in_features
pretrained_model5.fc = nn.Linear(num_features, 50)

iters5, val_loss5, val_acc5, train_acc5, train_loss5 = train_res_net(
    pretrained_model5,
    train_data_loader,
    val_data_loader, batch_size = 64, learn_rate = 0.001)

print("")
plot_results(iters5, train_acc5, val_acc5, "Accuracy-50 layers, 0.001 lr")
plot_results(iters5, train_loss5, val_loss5, "Loss-50 layers, 0.001 lr")

selftrained_model = models.resnet34(pretrained=False)

num_features = selftrained_model.fc.in_features
selftrained_model.fc = nn.Linear(num_features, 50)

iters, val_loss, val_acc, train_acc, train_loss = train_res_net(
    selftrained_model,
    train_data_loader,
    val_data_loader)

print("")
plot_results(iters, train_acc, val_acc, "Accuracy-selftrained")
plot_results(iters, train_loss, val_loss, "Loss-selftrained")

def get_accuracy(model, data_loader):
    correct = 0
    total = 0
    for imgs, labels in data_loader:
        labels = get_adjusted_label(labels)
        use_cuda = True
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()

        output = model(imgs)
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

print("Test accuracy is:",get_accuracy(pretrained_model, test_data_loader))

"""## Visualize results"""

def store_model(name, model):
  # store the current model
  save_model_directory = home_path + 'models/'
  os.chdir(save_model_directory)
  torch.save(model.state_dict(), name)
  os.chdir(home_path)

store_model("pretrained_model_epochs10_lr0.01_bs32", pretrained_model)

store_model("pretrained_model_50layers_epochs10_lr0.01_bs32", pretrained_model4) #Model4. It had slightly higher validation accuracy.

def load_model(name):
  # load model
  save_model_directory = home_path + 'models/'
  os.chdir(save_model_directory)

  final_model = models.resnet34(pretrained=True)
  num_features = final_model.fc.in_features
  final_model.fc = nn.Linear(num_features, 50)

  state = torch.load(name)
  final_model.load_state_dict(state)

  os.chdir(home_path)
  return final_model

final_model= load_model("pretrained_model_epochs10_lr0.01_bs32")

print(final_model)

def open_image(test_image_path, folder='test/'):
  """
  - Sample input: 'Audi 100 Sedan 1994'
  """
  original_path = os.path.abspath(os.getcwd()) #save current directory
  overall_path = path + folder + test_image_path #contains several images that
  # of type passed in as the argument
  os.chdir(overall_path)

  image_nos = os.listdir(overall_path) #all files containing pngs
   # just take a random one
  image_index = random.choice(image_nos)
  PIL_img = Image.open(image_index)

  transform = transforms.Compose([transforms.Resize((244,244)),
                                  transforms.ToTensor(),
                                  transforms.Normalize(
                                      (0.5, 0.5, 0.5),
                                      (0.5, 0.5, 0.5))
                                  ])
  img = transform(PIL_img)
  numpy_img = np.array(img)
  #going back to original direction
  os.chdir(original_path)

  image = numpy_img.transpose((1, 2, 0))

  # Undo preprocessing
  mean = np.array([0.5, 0.5, 0.5])
  std = np.array([0.5, 0.5, 0.5])
  image = std * image + mean

  # Image needs to be clipped between 0 and 1 or it looks like noise when displayed
  image = np.clip(image, 0, 1)

  plt.figure()
  # plt.title(test_image_path)
  plt.imshow(image)
  return torch.from_numpy(numpy_img).type(torch.FloatTensor)

tensor_imp = open_image('Bugatti Veyron 16.4 Coupe 2009')

def predict_image(model, car_model, top_elements=3):
  model.eval()
  print("Opening image of model")
  tensor_img = open_image(car_model)

  print("Top " + str(top_elements) + " brands")

  tensor_img_adjust = tensor_img.unsqueeze(0)
  output = model(tensor_img_adjust)
  classification = get_brand_name_from_adjusted_class(output[0].argmax().item())
  top_items = output[0].sort(descending=True)
  for i in range(top_elements):
    print(str(i+1) + ": " + get_brand_name_from_adjusted_class(top_items[1][i].item()))

  plt.title(classification)
  plt.show()

items_count = 3
for i in range(items_count):
  predict_image(final_model, 'Bugatti Veyron 16.4 Convertible 2009')

for i in range(items_count):
  predict_image(final_model, 'Ferrari California Convertible 2012')

for i in range(items_count):
  predict_image(final_model, 'BMW 3 Series Sedan 2012')

for i in range(items_count):
  predict_image(final_model, 'smart fortwo Convertible 2012')

for i in range(items_count):
  predict_image(final_model, 'Chevrolet Monte Carlo Coupe 2007')

"""
- Sample input: 'Audi 100 Sedan 1994'
"""
original_path = os.path.abspath(os.getcwd()) #save current directory
overall_path = home_path + '/car_data/random_pics/'
os.chdir(overall_path)
image_nos = os.listdir(overall_path) #all files containing pngs
transform = transforms.Compose([transforms.Resize((224,224)),
                                transforms.ToTensor(),
                                transforms.Normalize(
                                    (0.5, 0.5, 0.5),
                                    (0.5, 0.5, 0.5))
                                ])
for i in range(len(image_nos)):
  image_index = image_nos[i]
  PIL_img = Image.open(image_index)
  img = transform(PIL_img)
  numpy_img = np.array(img)
  image = numpy_img.transpose((1, 2, 0))
  # Undo preprocessing
  mean = np.array([0.5, 0.5, 0.5])
  std = np.array([0.5, 0.5, 0.5])
  image = std * image + mean
  # Image needs to be clipped between 0 and 1 or it looks like noise when displayed
  image = np.clip(image, 0, 1)
  plt.figure()
  # plt.title(test_image_path)
  plt.imshow(image)
  tensor_img = torch.from_numpy(numpy_img).type(torch.FloatTensor)
  final_model.eval()
  print("Opening image of model")
  tensor_img_adjust = tensor_img.unsqueeze(0)
  output = final_model(tensor_img_adjust)
  classification = get_brand_name_from_adjusted_class(output[0].argmax().item())
  top_items = output[0].sort(descending=True)
  for i in range(3):
    print(str(i+1) + ": " + get_brand_name_from_adjusted_class(top_items[1][i].item()))

  plt.title(classification)
  plt.show()

#going back to original direction
os.chdir(original_path)